{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AE_27_200_200_200_18_200_200_200_27 best_AE_bn_LeakyReLU_bs4096_lr1e-02_wd1e-02\n",
      "Test data shape: torch.Size([100000, 27])\n",
      "Average elapsed cycles: 3875077847.1\n",
      "Average elapsed cycles per jet: 38750.778471\n",
      "AE_27_200_200_200_16_200_200_200_27 best_AE_bn_LeakyReLU_bs4096_lr3e-02_wd1e-04\n",
      "Test data shape: torch.Size([100000, 27])\n",
      "Average elapsed cycles: 4122911242.2\n",
      "Average elapsed cycles per jet: 41229.112422\n",
      "AE_27_200_200_200_14_200_200_200_27 best_AE_bn_LeakyReLU_bs4096_lr1e-02_wd1e-02\n",
      "Test data shape: torch.Size([100000, 27])\n",
      "Average elapsed cycles: 4350450682.8\n",
      "Average elapsed cycles per jet: 43504.506828\n",
      "AE_27_200_200_200_12_200_200_200_27 best_AE_bn_LeakyReLU_bs4096_lr1e-03_wd1e-01\n",
      "Test data shape: torch.Size([100000, 27])\n",
      "Average elapsed cycles: 4420806455.4\n",
      "Average elapsed cycles per jet: 44208.064554\n",
      "AE_27_200_200_200_20_200_200_200_27 best_AE_bn_LeakyReLU_bs4096_lr1e-02_wd1e-02\n",
      "Test data shape: torch.Size([100000, 27])\n",
      "Average elapsed cycles: 3752596281.6\n",
      "Average elapsed cycles per jet: 37525.962816\n",
      "AE_27_200_200_200_10_200_200_200_27 best_AE_bn_LeakyReLU_bs4096_lr1e-03_wd1e-02\n",
      "Test data shape: torch.Size([100000, 27])\n",
      "Average elapsed cycles: 4597200777.3\n",
      "Average elapsed cycles per jet: 45972.007773000005\n",
      "AE_27_200_200_200_8_200_200_200_27 best_AE_bn_LeakyReLU_bs4096_lr1e-02_wd1e-04\n",
      "Test data shape: torch.Size([100000, 27])\n",
      "Average elapsed cycles: 4411681819.2\n",
      "Average elapsed cycles per jet: 44116.818192\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "BIN = '../'\n",
    "sys.path.append(BIN)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pickle\n",
    "import my_matplotlib_style as ms\n",
    "from scipy import stats\n",
    "import utils\n",
    "\n",
    "import hwcounter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from fastai.callbacks.tracker import SaveModelCallback\n",
    "\n",
    "from fastai import basic_train, basic_data\n",
    "from fastai.callbacks import ActivationStats\n",
    "from fastai import train as tr\n",
    "\n",
    "from nn_utils import get_data, RMSELoss\n",
    "from utils import plot_activations\n",
    "\n",
    "from nn_utils import AE_basic, AE_bn_LeakyReLU\n",
    "\n",
    "mpl.rc_file(BIN + 'my_matplotlib_rcparams')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_pickle(BIN + 'processed_data/aod/all_jets_train_27D_5_percent.pkl')\n",
    "test = pd.read_pickle(BIN + 'processed_data/aod/all_jets_test_27D_5_percent.pkl')\n",
    "\n",
    "#Remove irrelevant columns\n",
    "#train.pop('JetGhostArea')\n",
    "#test.pop('JetGhostArea')\n",
    "#train.pop('BchCorrCell')\n",
    "#test.pop('BchCorrCell')\n",
    "\n",
    "# Remove extreme/bad jets\n",
    "train = utils.filter_jets(train)\n",
    "test = utils.filter_jets(test)\n",
    "\n",
    "# Normalize\n",
    "train_mean = train.mean()\n",
    "train_std = train.std()\n",
    "\n",
    "train, test = utils.custom_normalization(train, test)\n",
    "\n",
    "train_x = train\n",
    "test_x = test\n",
    "train_y = train_x  # y = x since we are building and AE\n",
    "test_y = test_x\n",
    "\n",
    "train_ds = TensorDataset(torch.tensor(train_x.values), torch.tensor(train_y.values))\n",
    "valid_ds = TensorDataset(torch.tensor(test_x.values), torch.tensor(test_y.values))\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs=1024)\n",
    "db = basic_data.DataBunch(train_dl, valid_dl)\n",
    "\n",
    "module_name = 'AE_bn_LeakyReLU'\n",
    "module = AE_bn_LeakyReLU\n",
    "grid_search_folder = \"AE_bn_LeakyReLU_AOD_grid_search_custom_normalization_1500epochs/\"\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "#The folder to analyse\n",
    "model_folder_name = \"AE_27_200_200_200_18_200_200_200_27\"\n",
    "\n",
    "plt.close('all')\n",
    "\n",
    "#Just alter this if you want to iterate through every model\n",
    "#for model_folder in [x for x in os.scandir(grid_search_folder) if x.name == model_folder_name]:\n",
    "for model_folder in os.scandir(grid_search_folder):\n",
    "    if model_folder.is_dir():\n",
    "        for train_folder in os.scandir(grid_search_folder + model_folder.name):\n",
    "            if train_folder.is_dir() and train_folder.name == 'models':\n",
    "                plt.close('all')\n",
    "\n",
    "                #Find the best model\n",
    "                for f in os.scandir(grid_search_folder + model_folder.name + '/' + train_folder.name + '/'):\n",
    "                    if f.name[:4] == \"best\":\n",
    "                        saved_model_fname = f.name[:-4]\n",
    "                        print(model_folder.name + \" \" + f.name[:-4])\n",
    "\n",
    "                #Load model\n",
    "                nodes = model_folder.name.split('AE_')[1].split('_')\n",
    "                nodes = [int(x) for x in nodes]\n",
    "                model = module(nodes)\n",
    "                learn = basic_train.Learner(data=db, model=model, loss_func=loss_func, true_wd=True)\n",
    "                learn.model_dir = grid_search_folder + model_folder.name + '/' + 'models/'\n",
    "                learn.load(saved_model_fname)\n",
    "                #model.load_state_dict(torch.load(path_to_saved_model))\n",
    "                learn.model.eval()\n",
    "\n",
    "                repeats = 10\n",
    "                start = hwcounter.count()\n",
    "                \n",
    "                for i in range(0,repeats):\n",
    "                    # Histograms\n",
    "                    idxs = (0, 100000)  # Choose events to compare\n",
    "                    data = torch.tensor(test_x[idxs[0]:idxs[1]].values)\n",
    "                    #Note, float conversion\n",
    "                    pred = model(data.float()).detach().numpy()\n",
    "                    pred = np.multiply(pred, train_std.values)\n",
    "                    pred = np.add(pred, train_mean.values)\n",
    "                    data = np.multiply(data, train_std.values)\n",
    "                    data = np.add(data, train_mean.values)\n",
    "                \n",
    "                elapsed = hwcounter.count_end() - start\n",
    "                print(\"Test data shape: \" + str(data.shape))\n",
    "                print(\"Average elapsed cycles: \" + str(elapsed/repeats))\n",
    "                print(\"Average elapsed cycles per jet: \" + str(elapsed/data.shape[0]/repeats ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
